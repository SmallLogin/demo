{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-a ALGORITHM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Lenovo\\AppData\\Roaming\\jupyter\\runtime\\kernel-6df18394-1300-4505-9bc6-f8d1c7137fa8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3-5.2.0-Windows-x86_64\\anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/python\n",
    "\n",
    "\"\"\"Surveillance Demo: Tracking Pedestrians in Camera Feed\n",
    "\n",
    "The application opens a video (could be a camera or a video file)\n",
    "and tracks pedestrians in the video.\n",
    "\"\"\"\n",
    "# __author__ = \"joe minichino\"\n",
    "# __copyright__ = \"property of mankind.\"\n",
    "# __license__ = \"MIT\"\n",
    "# __version__ = \"0.0.1\"\n",
    "# __maintainer__ = \"Joe Minichino\"\n",
    "# __email__ = \"joe.minichino@gmail.com\"\n",
    "# __status__ = \"Development\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-a\", \"--algorithm\",\n",
    "    help = \"m (or nothing) for meanShift and c for camshift\")\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "def center(points):\n",
    "    \"\"\"calculates centroid of a given matrix\"\"\"\n",
    "    x = (points[0][0] + points[1][0] + points[2][0] + points[3][0]) / 4\n",
    "    y = (points[0][1] + points[1][1] + points[2][1] + points[3][1]) / 4\n",
    "    return np.array([np.float32(x), np.float32(y)], np.float32)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "class Pedestrian():\n",
    "  \"\"\"Pedestrian class\n",
    "\n",
    "  each pedestrian is composed of a ROI, an ID and a Kalman filter\n",
    "  so we create a Pedestrian class to hold the object state\n",
    "  \"\"\"\n",
    "  def __init__(self, id, frame, track_window):\n",
    "    \"\"\"init the pedestrian object with track window coordinates\"\"\"\n",
    "    # set up the roi\n",
    "    self.id = int(id)\n",
    "    x,y,w,h = track_window\n",
    "    self.track_window = track_window\n",
    "    self.roi = cv2.cvtColor(frame[y:y+h, x:x+w], cv2.COLOR_BGR2HSV)\n",
    "    roi_hist = cv2.calcHist([self.roi], [0], None, [16], [0, 180])\n",
    "    self.roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # set up the kalman\n",
    "    self.kalman = cv2.KalmanFilter(4,2)\n",
    "    self.kalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)\n",
    "    self.kalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)\n",
    "    self.kalman.processNoiseCov = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32) * 0.03\n",
    "    self.measurement = np.array((2,1), np.float32) \n",
    "    self.prediction = np.zeros((2,1), np.float32)\n",
    "    self.term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "    self.center = None\n",
    "    self.update(frame)\n",
    "    \n",
    "  def __del__(self):\n",
    "    print (\"Pedestrian %d destroyed\" % self.id)\n",
    "\n",
    "  def update(self, frame):\n",
    "    # print \"updating %d \" % self.id\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    back_project = cv2.calcBackProject([hsv],[0], self.roi_hist,[0,180],1)\n",
    "    \n",
    "    if args.get(\"algorithm\") == \"c\":\n",
    "      ret, self.track_window = cv2.CamShift(back_project, self.track_window, self.term_crit)\n",
    "      pts = cv2.boxPoints(ret)\n",
    "      pts = np.int0(pts)\n",
    "      self.center = center(pts)\n",
    "      cv2.polylines(frame,[pts],True, 255,1)\n",
    "      \n",
    "    if not args.get(\"algorithm\") or args.get(\"algorithm\") == \"m\":\n",
    "      ret, self.track_window = cv2.meanShift(back_project, self.track_window, self.term_crit)\n",
    "      x,y,w,h = self.track_window\n",
    "      self.center = center([[x,y],[x+w, y],[x,y+h],[x+w, y+h]])  \n",
    "      cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2)\n",
    "\n",
    "    self.kalman.correct(self.center)\n",
    "    prediction = self.kalman.predict()\n",
    "    cv2.circle(frame, (int(prediction[0]), int(prediction[1])), 4, (255, 0, 0), -1)\n",
    "    # fake shadow\n",
    "    cv2.putText(frame, \"ID: %d -> %s\" % (self.id, self.center), (11, (self.id + 1) * 25 + 1),\n",
    "        font, 0.6,\n",
    "        (0, 0, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA)\n",
    "    # actual info\n",
    "    cv2.putText(frame, \"ID: %d -> %s\" % (self.id, self.center), (10, (self.id + 1) * 25),\n",
    "        font, 0.6,\n",
    "        (0, 255, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA)\n",
    "\n",
    "def main():\n",
    "  # camera = cv2.VideoCapture(path.join(path.dirname(__file__), \"traffic.flv\"))\n",
    "  camera = cv2.VideoCapture(\"768x576.avi\")\n",
    "  # camera = cv2.VideoCapture(path.join(path.dirname(__file__), \"..\", \"movie.mpg\"))\n",
    "  # camera = cv2.VideoCapture(0)\n",
    "  history = 20\n",
    "  # KNN background subtractor\n",
    "  bs = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "  # MOG subtractor\n",
    "  # bs = cv2.bgsegm.createBackgroundSubtractorMOG(history = history)\n",
    "  # bs.setHistory(history)\n",
    "\n",
    "  # GMG\n",
    "  # bs = cv2.bgsegm.createBackgroundSubtractorGMG(initializationFrames = history)\n",
    "  \n",
    "  cv2.namedWindow(\"surveillance\")\n",
    "  pedestrians = {}\n",
    "  firstFrame = True\n",
    "  frames = 0\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "  out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "  while True:\n",
    "    print (\" -------------------- FRAME %d --------------------\" % frames)\n",
    "    grabbed, frame = camera.read()\n",
    "    if (grabbed is False):\n",
    "      print (\"failed to grab frame.\")\n",
    "      break\n",
    "\n",
    "    fgmask = bs.apply(frame)\n",
    "\n",
    "    # this is just to let the background subtractor build a bit of history\n",
    "    if frames < history:\n",
    "      frames += 1\n",
    "      continue\n",
    "\n",
    "\n",
    "    th = cv2.threshold(fgmask.copy(), 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    th = cv2.erode(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations = 2)\n",
    "    dilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,3)), iterations = 2)\n",
    "    image, contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    counter = 0\n",
    "    for c in contours:\n",
    "      if cv2.contourArea(c) > 500:\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 1)\n",
    "        # only create pedestrians in the first frame, then just follow the ones you have\n",
    "        if firstFrame is True:\n",
    "          pedestrians[counter] = Pedestrian(counter, frame, (x,y,w,h))\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "    for i, p in pedestrians.items():\n",
    "      p.update(frame)\n",
    "    \n",
    "    firstFrame = False\n",
    "    frames += 1\n",
    "\n",
    "    cv2.imshow(\"surveillance\", frame)\n",
    "    out.write(frame)\n",
    "    if cv2.waitKey(110) & 0xff == 27:\n",
    "        break\n",
    "  out.release()\n",
    "  camera.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
